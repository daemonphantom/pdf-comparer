"""
LLM-based comparison module for PDF-extracted content. Detects changes very granularly and detailed. Good for detecting changes on word-level.
Uses LLM to intelligently identify meaningful changes between two JSON files.
"""
import json
from typing import List, Dict, Any, Optional

from mvp.llm.llm_provider import OllamaProvider


class LLMVersionComparator:
    """Compares two versions of PDF-extracted JSON content using LLM for intelligent change detection."""
    
    def __init__(self, llm_provider: Optional[OllamaProvider] = None):
        """Initialize with LLM provider."""
        self.llm_provider = llm_provider or OllamaProvider()

        self.change_detection_prompt = """Du bist ein pr√§ziser Diff-Analysator. Vergleiche A (ALT) und B (NEU).

        AUSGABE: Nur ein JSON-Array, nichts anderes. Keine Erkl√§rungen davor oder danach.

        IGNORIERE V√ñLLIG:
        - Aufz√§hlungszeichen (-, ‚Ä¢, *, Zahlen)
        - Whitespace/Leerzeichen/Zeilenumbr√ºche
        - Gro√ü-/Kleinschreibung bei identischem Inhalt

        MELDE IMMER:
        - Zahlen√§nderungen (inkl. Prozent, ‚Ç¨, Mengen)
        - Datum/Zeit√§nderungen (Formatiere alle Daten im Format DD-MM-YYYY)
        - URLs
        - Negationen/Modalverben (nicht, kein, nur, muss, darf, soll, mindestens)
        - Inhaltliche Wort-/Phrasen√§nderungen

        FORMAT (nur dieses JSON-Array ausgeben):
        [
        {"typ":"SUBSTITUTION","alt":"alter Text","neu":"neuer Text"},
        {"typ":"EINFUEGUNG","neu":"hinzugef√ºgter Text"},
        {"typ":"LOESCHUNG","alt":"entfernter Text"},
        {"typ":"ZAHL","alt":"5","neu":"10"},
        {"typ":"DATUM","alt":"2024-01-15","neu":"2024-02-20"},
        {"typ":"URL","alt":"http://old.com","neu":"http://new.com"}
        ]

        REGEL: Minimale Spans. Bei "Hallo Welt" ‚Üí "Hallo Universum": {"typ":"SUBSTITUTION","alt":"Welt","neu":"Universum"}

        INPUT FOLGT:"""

        self.table_comparison_prompt = """Du vergleichst zwei Tabellen: A=ALT, B=NEU. Identifiziere alle Unterschiede in Struktur und Inhalt.

        Ausgabeformat (JSON-Liste):
        [
        {"typ":"header_change","alt":["spalte1","spalte2"],"neu":["spalte1","spalte3"]},
        {"typ":"row_added","neu":["wert1","wert2","wert3"]},
        {"typ":"row_removed","alt":["wert1","wert2","wert3"]},
        {"typ":"cell_change","zeile":0,"spalte":1,"alt":"alter_wert","neu":"neuer_wert"},
        {"typ":"structure_change","beschreibung":"Anzahl Spalten ge√§ndert von 3 auf 4"}
        ]

        Regeln:
        - Erfasse auch kleine √Ñnderungen in Zellwerten
        - Ignoriere reine Formatierungsunterschiede
        - Kein Zusatztext, nur das JSON.

        Eingabe folgt als:
        A: <table1>
        B: <table2>"""
    
    def process_change_tracking_json(self, change_tracking_file: str) -> Dict[str, Any]:
        """
        Process change tracking JSON from align_json.py and analyze changes.
        !!! Args: change_tracking_file: Path to the JSON file generated by align_json.py !!!
        """
        print(f"üîç Loading change tracking from {change_tracking_file}")
        
        with open(change_tracking_file, 'r', encoding='utf-8') as f:
            change_tracking = json.load(f)
        
        metadata = change_tracking.get("comparison_metadata", {})
        slides = change_tracking.get("slides", [])
        detailed_changes = []
        
        for slide in slides:
            change_type = slide.get("change_type")
            
            if change_type == "removed":
                # Slide was deleted - no llm
                detailed_changes.append({
                    "change_type": "removed",
                    "old_slide_index": slide.get("old_slide_index"),
                    "old_slide_title": slide.get("old_slide", {}).get("title", "Untitled"),
                    "old_page_number": slide.get("old_slide", {}).get("page_number"),
                    "changes": [],
                    "note": "Entire slide was removed"
                })
                
            elif change_type == "added":
                # Slide was added - no llm
                detailed_changes.append({
                    "change_type": "added",
                    "new_slide_index": slide.get("new_slide_index"),
                    "new_slide_title": slide.get("new_slide", {}).get("title", "Untitled"),
                    "new_page_number": slide.get("new_slide", {}).get("page_number"),
                    "changes": [],
                    "note": "Entire slide was added"
                })
                
            elif change_type == "unchanged":
                # Slides are identical - no llm
                detailed_changes.append({
                    "change_type": "unchanged",
                    "old_slide_index": slide.get("old_slide_index"),
                    "new_slide_index": slide.get("new_slide_index"),
                    "slide_title": slide.get("new_slide", {}).get("title", "Untitled"),
                    "similarity_score": slide.get("similarity_score"),
                    "changes": [],
                    "note": "Slides are identical, no changes detected"
                })
                
            elif change_type == "modified":
                # Slides exist in both but have changes - with llm
                print(f"üîé Analyzing modified slide: {slide.get('old_slide', {}).get('title', 'Untitled')}")
                changes = self.analyze_slide_changes(
                    slide.get("old_slide"),
                    slide.get("new_slide")
                )
                detailed_changes.append({
                    "change_type": "modified",
                    "old_slide_index": slide.get("old_slide_index"),
                    "new_slide_index": slide.get("new_slide_index"),
                    "slide_title": slide.get("new_slide", {}).get("title", "Untitled"),
                    "similarity_score": slide.get("similarity_score"),
                    "changes": changes
                })
                
            elif change_type == "merge":
                # Multiple old slides merged into one
                print(f"üîé Analyzing merged slide: {slide.get('new_slide', {}).get('title', 'Untitled')}")
                changes = self.analyze_merge(
                    slide.get("old_slides", []),
                    slide.get("new_slide")
                )
                detailed_changes.append({
                    "change_type": "merge",
                    "old_slide_indices": slide.get("old_slide_indices", []),
                    "new_slide_index": slide.get("new_slide_index"),
                    "new_slide_title": slide.get("new_slide", {}).get("title", "Untitled"),
                    "similarity_scores": slide.get("similarity_scores", []),
                    "changes": changes
                })
                
            elif change_type == "split":
                # One old slide split into multiple
                print(f"üîé Analyzing split slide: {slide.get('old_slide', {}).get('title', 'Untitled')}")
                changes = self.analyze_split(
                    slide.get("old_slide"),
                    slide.get("new_slides", [])
                )
                detailed_changes.append({
                    "change_type": "split",
                    "old_slide_index": slide.get("old_slide_index"),
                    "new_slide_indices": slide.get("new_slide_indices", []),
                    "old_slide_title": slide.get("old_slide", {}).get("title", "Untitled"),
                    "similarity_scores": slide.get("similarity_scores", []),
                    "changes": changes
                })
        
        # Generate report
        report = {
            "metadata": metadata,
            "total_slides_analyzed": len(slides),
            "slides_with_content_changes": len([s for s in detailed_changes if s.get("changes")]),
            "detailed_changes": detailed_changes
        }
        
        return report
    
    def analyze_slide_changes(self, old_slide: Dict, new_slide: Dict) -> List[Dict[str, Any]]:
        """Analyze changes between two individual slides using LLM."""
        all_changes = []
        
        # Compare main content (URLs included)
        content_changes = self.detect_content_changes_llm(
            old_slide.get("content", ""),
            new_slide.get("content", "")
        )
        all_changes.extend(content_changes)
        
        # Compare tables
        table_changes = self.compare_tables_llm(
            old_slide.get("tables", []),
            new_slide.get("tables", [])
        )
        all_changes.extend(table_changes)
        
        return all_changes
    
    def analyze_merge(self, old_slides: List[Dict], new_slide: Dict) -> List[Dict[str, Any]]:
        """Analyze what happened when multiple slides were merged into one."""
        return [{
            "type": "merge_detected",
            "description": f"{len(old_slides)} slides were merged into one",
            "note": "Individual changes not analyzed for merges."
        }]
    
    def analyze_split(self, old_slide: Dict, new_slides: List[Dict]) -> List[Dict[str, Any]]:
        """Analyze what happened when one slide was split into multiple."""
        return [{
            "type": "split_detected",
            "description": f"Slide was split into {len(new_slides)} new slides",
            "note": "Individual changes not analyzed for splits."
        }]
    
    
    def detect_content_changes_llm(self, content1: str, content2: str) -> List[Dict[str, Any]]:
        """LLM to detect meaningful changes between content."""
        if not content1 and not content2:
            return []
        
        if not content1:
            return [{'type': 'content_added', 'new_content': content2}]
        
        if not content2:
            return [{'type': 'content_removed', 'old_content': content1}]
        
        # contents are the same
        if content1 == content2:
            return []
        
        try:
            # Prepare for LLM
            llm_input = f"A: {content1}\nB: {content2}"
            
            # Get changes from LLM
            response = self.llm_provider.chat(
                messages=[
                    {"role": "system", "content": self.change_detection_prompt},
                    {"role": "user", "content": llm_input},
                ],
                options={
                    "num_predict": 8192,  # Allow longer responses
                    "temperature": 0.7
                }
            )
            
            # Clean up
            response = response.strip().strip('"\'')
            
            # Parse response
            try:
                llm_changes = json.loads(response)
                if isinstance(llm_changes, list):
                    # Convert format
                    changes = []
                    for change in llm_changes:
                        change_dict = {
                            'type': change.get('typ', 'unknown_change'),
                            'description': self._format_change_description(change)
                        }
                        
                        if 'alt' in change:
                            change_dict['old_text'] = change['alt']
                        if 'neu' in change:
                            change_dict['new_text'] = change['neu']
                        
                        changes.append(change_dict)
                    
                    return changes
                else:
                    print(f"‚ö†Ô∏è Unexpected LLM response format: {response}")
                    return []
            except json.JSONDecodeError:
                print(f"‚ö†Ô∏è Failed to parse LLM response as JSON: {response}")
                return []
        except Exception as e:
            print(f"‚ùå Error using LLM for content comparison: {e}")
            # Fallback
            return [{'type': 'content_change', 'description': 'Content was modified', 
                    'old_content': content1[:200] + "..." if len(content1) > 200 else content1,
                    'new_content': content2[:200] + "..." if len(content2) > 200 else content2}]
    
    def _format_change_description(self, change: Dict) -> str:
        """Format a change description based on the change type."""
        typ = change.get('typ', 'unknown')
        
        # New prompt format types
        if typ == 'SUBSTITUTION':
            return f"{change.get('alt')} ‚Üí {change.get('neu')}"
        elif typ == 'EINFUEGUNG':
            return f"added: '{change.get('neu')}'"
        elif typ == 'LOESCHUNG':
            return f"removed: '{change.get('alt')}'"
        elif typ == 'ZAHL':
            return f"{change.get('alt')} ‚Üí {change.get('neu')}"
        elif typ == 'DATUM':
            return f"{change.get('alt')} ‚Üí {change.get('neu')}"
        elif typ == 'URL':
            return f"{change.get('alt')} ‚Üí {change.get('neu')}"
        else:
            return f"Change detected: {change}"
    
    def compare_tables_llm(self, tables1: List[Dict], tables2: List[Dict]) -> List[Dict[str, Any]]:
        """Compare tables using LLM for intelligent detection."""
        changes = []
        
        # Handle different number of tables
        if len(tables1) != len(tables2):
            changes.append({
                'type': 'table_count_change',
                'old_count': len(tables1),
                'new_count': len(tables2),
                'description': f'Number of tables changed from {len(tables1)} to {len(tables2)}'
            })
        
        # Compare each table pair using LLM
        for i, (table1, table2) in enumerate(zip(tables1, tables2)):
            table_changes = self.compare_single_table_llm(table1, table2, i)
            changes.extend(table_changes)
        
        # Handle extra tables in either version
        if len(tables1) > len(tables2):
            for i in range(len(tables2), len(tables1)):
                changes.append({
                    'type': 'table_removed',
                    'table_index': i,
                    'description': f'Table {i + 1} was removed'
                })
        elif len(tables2) > len(tables1):
            for i in range(len(tables1), len(tables2)):
                changes.append({
                    'type': 'table_added',
                    'table_index': i,
                    'description': f'Table {i + 1} was added'
                })
        
        return changes
    
    def compare_single_table_llm(self, table1: Dict, table2: Dict, table_index: int) -> List[Dict[str, Any]]:
        """Compare two individual tables using LLM."""
        changes = []
        
        try:
            # Convert tables to a comparable format
            table1_str = self._table_to_string(table1)
            table2_str = self._table_to_string(table2)
            
            # If tables are identical, no changes
            if table1_str == table2_str:
                return []
            
            # Prepare input for LLM
            llm_input = f"A: {table1_str}\nB: {table2_str}"
            
            # Get changes from LLM
            response = self.llm_provider.chat(
                messages=[
                    {"role": "system", "content": self.table_comparison_prompt},
                    {"role": "user", "content": llm_input},
                ]
            )
            
            # Clean up response
            response = response.strip().strip('"\'')
            
            # Parse JSON response
            try:
                llm_changes = json.loads(response)
                if isinstance(llm_changes, list):
                    # Convert LLM format to our internal format
                    for change in llm_changes:
                        change_dict = {
                            'type': f"table_{change.get('typ', 'unknown_change')}",
                            'table_index': table_index,
                            'description': self._format_table_change_description(change, table_index)
                        }
                        
                        # Add specific fields based on change type
                        if 'zeile' in change:
                            change_dict['row'] = change['zeile']
                        if 'spalte' in change:
                            change_dict['column'] = change['spalte']
                        if 'alt' in change:
                            change_dict['old_value'] = change['alt']
                        if 'neu' in change:
                            change_dict['new_value'] = change['neu']
                        if 'beschreibung' in change:
                            change_dict['description'] = change['beschreibung']
                        
                        changes.append(change_dict)
                    
                    return changes
                else:
                    print(f"‚ö†Ô∏è Unexpected LLM table response format: {response}")
                    return []
                    
            except json.JSONDecodeError:
                print(f"‚ö†Ô∏è Failed to parse LLM table response as JSON: {response}")
                return []
                
        except Exception as e:
            print(f"‚ùå Error using LLM for table comparison: {e}")
            # Fallback: simple table change detection
            return [{
                'type': 'table_change',
                'table_index': table_index,
                'description': f'Table {table_index + 1} was modified'
            }]
    
    def _table_to_string(self, table: Dict) -> str:
        """Convert table dictionary to string representation for LLM comparison."""
        lines = []
        
        # Headers
        headers = table.get('headers', [])
        if headers:
            lines.append("Headers: " + " | ".join(headers))
        
        # Rows
        rows = table.get('rows', [])
        for i, row in enumerate(rows):
            if isinstance(row, list):
                lines.append(f"Row {i}: " + " | ".join(str(cell) for cell in row))
            else:
                lines.append(f"Row {i}: {row}")
        
        return "\n".join(lines)
    
    def _format_table_change_description(self, change: Dict, table_index: int) -> str:
        """Format a table change description."""
        typ = change.get('typ', 'unknown')
        table_num = table_index + 1
        
        if typ == 'header_change':
            return f"Table {table_num}: Headers changed from {change.get('alt')} to {change.get('neu')}"
        elif typ == 'row_added':
            return f"Table {table_num}: Row added: {change.get('neu')}"
        elif typ == 'row_removed':
            return f"Table {table_num}: Row removed: {change.get('alt')}"
        elif typ == 'cell_change':
            row = change.get('zeile', '?')
            col = change.get('spalte', '?')
            return f"Table {table_num}: Cell ({row}, {col}) changed from '{change.get('alt')}' to '{change.get('neu')}'"
        elif typ == 'structure_change':
            return f"Table {table_num}: {change.get('beschreibung', 'Structure changed')}"
        else:
            return f"Table {table_num}: {change}"


def main():
    import argparse
    parser = argparse.ArgumentParser(
        description="Analyze slide changes using LLM for intelligent change detection",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('json', nargs='?', help='JSON file generated by align_json.py')
    parser.add_argument('-o', '--output', help='Output file for detailed analysis report (default: changes_detailed.json)')    
    args = parser.parse_args()
    if not args.output:
        args.output = "changes_detailed.json"
        
    try:            
        # Initialize LLM provider
        llm_provider = OllamaProvider()
        
        # Process change tracking
        comparator = LLMVersionComparator(llm_provider)
        report = comparator.process_change_tracking_json(args.json)
        
        # Save report
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"Detailed change analysis saved to: {args.output}")
        print(f"   Total slides analyzed: {report['total_slides_analyzed']}")
        print(f"   Slides with content changes: {report['slides_with_content_changes']}")
        
        change_types = {}
        for slide in report['detailed_changes']:
            change_type = slide['change_type']
            change_types[change_type] = change_types.get(change_type, 0) + 1
        
        print(f"\n   Change type breakdown:")
        for change_type, count in sorted(change_types.items()):
            print(f"     {change_type}: {count}")  
    except Exception as e:
        print(f"‚ùå Error during analysis: {e}")
        print("Make sure Ollama is running")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()